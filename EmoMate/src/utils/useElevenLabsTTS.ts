import { useState, useCallback, useEffect } from 'react';
import { useAudioPlayer } from 'expo-audio';
import * as FileSystem from 'expo-file-system';
import { ELEVENLABS_CONFIG, getElevenLabsApiKey } from '../constants/ai';

export interface UseElevenLabsTTSReturn {
  isSpeaking: boolean;
  isGenerating: boolean; // æ–°å¢ï¼šæ˜¯å¦æ­£åœ¨ç”Ÿæˆè¯­éŸ³
  error: string | null;
  speak: (text: string, voiceId?: string) => Promise<void>;
  stop: () => Promise<void>;
  currentSegment: string; // å½“å‰æ­£åœ¨æ’­æ”¾çš„è¯­éŸ³ç‰‡æ®µ
}

export const useElevenLabsTTS = (): UseElevenLabsTTSReturn => {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const [audioUri, setAudioUri] = useState<string | null>(null);
  const [isGenerating, setIsGenerating] = useState(false); // æ–°å¢ï¼šè¯­éŸ³ç”ŸæˆçŠ¶æ€
  const [playbackTimer, setPlaybackTimer] = useState<NodeJS.Timeout | null>(null);
  const [currentSegment, setCurrentSegment] = useState<string>(''); // å½“å‰æ’­æ”¾çš„è¯­éŸ³ç‰‡æ®µ
  
  // Initialize audio player with null to avoid native module errors
  const audioPlayer = useAudioPlayer(null);

  const createMockSegments = (text: string): {text: string, start: number, end: number}[] => {
    const segments: {text: string, start: number, end: number}[] = [];
    const sentences = text.split(/[ã€‚ï¼ï¼Ÿ]/);
    let currentTime = 0;
    
    for (const sentence of sentences) {
      if (sentence.trim()) {
        const duration = sentence.length * 0.15; // ä¼°ç®—æ¯ä¸ªå­—ç¬¦0.15ç§’
        segments.push({
          text: sentence.trim(),
          start: currentTime,
          end: currentTime + duration
        });
        currentTime += duration + 0.2; // æ·»åŠ ä¸€ç‚¹é—´éš”
      }
    }
    
    return segments;
  };

  const generateSpeechFile = async (text: string, voiceId?: string): Promise<string> => {
    const apiKey = getElevenLabsApiKey();
    if (!apiKey) {
      throw new Error('ElevenLabs APIå¯†é’¥æœªé…ç½®ã€‚è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ELEVENLABS_API_KEYã€‚');
    }

    const voice = voiceId || ELEVENLABS_CONFIG.voices[ELEVENLABS_CONFIG.defaultVoice];
    const url = `${ELEVENLABS_CONFIG.baseURL}/text-to-speech/${voice}`;
    
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶è·¯å¾„
    const fileName = `elevenlabs_${Date.now()}.mp3`;
    const fileUri = FileSystem.documentDirectory + fileName;

    // ä½¿ç”¨ XMLHttpRequest æ¥æ­£ç¡®å¤„ç†äºŒè¿›åˆ¶æ•°æ®
    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();
      xhr.open('POST', url, true);
      xhr.responseType = 'blob';
      
      // è®¾ç½®è¯·æ±‚å¤´
      xhr.setRequestHeader('Accept', 'audio/mpeg');
      xhr.setRequestHeader('Content-Type', 'application/json');
      xhr.setRequestHeader('xi-api-key', apiKey);
      
      xhr.onload = async () => {
        if (xhr.status === 200) {
          try {
            // å°† blob è½¬æ¢ä¸º base64 å¹¶ä¿å­˜åˆ°æ–‡ä»¶
            const reader = new FileReader();
            reader.onloadend = async () => {
              const base64data = reader.result as string;
              const base64Audio = base64data.split(',')[1]; // ç§»é™¤ data:audio/mpeg;base64, å‰ç¼€
              
              await FileSystem.writeAsStringAsync(fileUri, base64Audio, {
                encoding: FileSystem.EncodingType.Base64,
              });
              
              resolve(fileUri);
            };
            reader.readAsDataURL(xhr.response);
          } catch (error) {
            reject(new Error(`ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${error}`));
          }
        } else {
          reject(new Error(`ElevenLabs APIè°ƒç”¨å¤±è´¥: ${xhr.status}`));
        }
      };
      
      xhr.onerror = () => {
        reject(new Error('ç½‘ç»œè¯·æ±‚å¤±è´¥'));
      };
      
      // å‘é€è¯·æ±‚
      const postData = JSON.stringify({
        text: text,
        model_id: ELEVENLABS_CONFIG.defaultModel,
        voice_settings: ELEVENLABS_CONFIG.settings,
      });
      
      xhr.send(postData);
    });
  };

  const generateSpeechWithTimestamps = async (text: string, voiceId?: string): Promise<{audioUri: string, segments: {text: string, start: number, end: number}[]}> => {
    const apiKey = getElevenLabsApiKey();
    if (!apiKey) {
      throw new Error('ElevenLabs APIå¯†é’¥æœªé…ç½®ã€‚è¯·åœ¨ç¯å¢ƒå˜é‡ä¸­è®¾ç½®ELEVENLABS_API_KEYã€‚');
    }

    const voice = voiceId || ELEVENLABS_CONFIG.voices[ELEVENLABS_CONFIG.defaultVoice];
    const url = `${ELEVENLABS_CONFIG.baseURL}/text-to-speech/${voice}/stream/with-timestamps`;
    
    console.log('ğŸµ å¼€å§‹ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„è¯­éŸ³:', { text, voice, url });
    
    // åˆ›å»ºä¸´æ—¶æ–‡ä»¶è·¯å¾„
    const fileName = `elevenlabs_${Date.now()}.mp3`;
    const fileUri = FileSystem.documentDirectory + fileName;

    return new Promise((resolve, reject) => {
      const xhr = new XMLHttpRequest();
      xhr.open('POST', url, true);
      xhr.responseType = 'text';
      
      // è®¾ç½®è¯·æ±‚å¤´
      xhr.setRequestHeader('Accept', 'text/plain');
      xhr.setRequestHeader('Content-Type', 'application/json');
      xhr.setRequestHeader('xi-api-key', apiKey);
      
      let audioData = '';
      let segments: {text: string, start: number, end: number}[] = [];
      let processedLines = new Set<string>();
      
      xhr.onprogress = (event) => {
        const responseText = xhr.responseText;
        const lines = responseText.split('\n');
        
        for (const line of lines) {
          if (line.trim() && !processedLines.has(line)) {
            processedLines.add(line);
            try {
              const data = JSON.parse(line);
              console.log('ğŸ“¦ æ”¶åˆ°æµå¼æ•°æ®:', data);
              
              if (data.audio_base64) {
                audioData += data.audio_base64;
              }
              if (data.alignment && data.alignment.characters) {
                console.log('ğŸ”¤ å¤„ç†å­—ç¬¦å¯¹é½ä¿¡æ¯:', data.alignment.characters.length, 'ä¸ªå­—ç¬¦');
                // å¤„ç†å­—ç¬¦çº§åˆ«çš„å¯¹é½ä¿¡æ¯ï¼Œåˆå¹¶æˆå•è¯æˆ–çŸ­è¯­
                const chars = data.alignment.characters;
                let currentSegment = '';
                let segmentStart = 0;
                
                for (let i = 0; i < chars.length; i++) {
                  const char = chars[i];
                  if (currentSegment === '') {
                    segmentStart = char.start_time_seconds;
                  }
                  currentSegment += char.character;
                  
                  // å½“é‡åˆ°æ ‡ç‚¹ç¬¦å·æˆ–è¾¾åˆ°ä¸€å®šé•¿åº¦æ—¶ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„æ®µè½
                  if (char.character.match(/[ã€‚ï¼ï¼Ÿï¼Œï¼›ï¼š]/)) {
                    if (currentSegment.trim()) {
                      segments.push({
                        text: currentSegment.trim(),
                        start: segmentStart,
                        end: char.end_time_seconds
                      });
                      console.log('ğŸ“ æ·»åŠ æ®µè½:', currentSegment.trim(), `(${segmentStart}s - ${char.end_time_seconds}s)`);
                    }
                    currentSegment = '';
                  }
                }
                
                // å¤„ç†æœ€åä¸€ä¸ªæ®µè½
                if (currentSegment.trim()) {
                  const lastChar = chars[chars.length - 1];
                  segments.push({
                    text: currentSegment.trim(),
                    start: segmentStart,
                    end: lastChar.end_time_seconds
                  });
                  console.log('ğŸ“ æ·»åŠ æœ€åæ®µè½:', currentSegment.trim(), `(${segmentStart}s - ${lastChar.end_time_seconds}s)`);
                }
              }
            } catch (e) {
              console.log('âš ï¸ è§£æJSONå¤±è´¥:', line, e);
            }
          }
        }
      };
      
      xhr.onload = async () => {
        if (xhr.status === 200) {
          try {
            // ä¿å­˜éŸ³é¢‘æ–‡ä»¶
            if (audioData) {
              await FileSystem.writeAsStringAsync(fileUri, audioData, {
                encoding: FileSystem.EncodingType.Base64,
              });
              console.log('ğŸ’¾ éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜:', fileUri);
            }
            
            console.log('âœ… ç”Ÿæˆå®Œæˆï¼Œå…±', segments.length, 'ä¸ªæ®µè½');
            resolve({ audioUri: fileUri, segments });
          } catch (error) {
            reject(new Error(`ä¿å­˜éŸ³é¢‘æ–‡ä»¶å¤±è´¥: ${error}`));
          }
        } else {
          console.error('âŒ ElevenLabs APIè°ƒç”¨å¤±è´¥:', xhr.status, xhr.responseText);
          reject(new Error(`ElevenLabs APIè°ƒç”¨å¤±è´¥: ${xhr.status}`));
        }
      };
      
      xhr.onerror = () => {
        reject(new Error('ç½‘ç»œè¯·æ±‚å¤±è´¥'));
      };
      
      // å‘é€è¯·æ±‚
      const postData = JSON.stringify({
        text: text,
        model_id: ELEVENLABS_CONFIG.defaultModel,
        voice_settings: ELEVENLABS_CONFIG.settings,
      });
      
      xhr.send(postData);
    });
  };

  // Monitor audio player state changes
  useEffect(() => {
    // isSpeaking åªåœ¨å®é™…æ’­æ”¾éŸ³é¢‘æ—¶ä¸º true
    setIsSpeaking(audioPlayer.playing);
    
    // æ£€æŸ¥éŸ³é¢‘æ˜¯å¦æ’­æ”¾å®Œæˆï¼ˆcurrentTime >= durationï¼‰
    if (!audioPlayer.playing && audioPlayer.duration > 0 && audioPlayer.currentTime >= audioPlayer.duration - 0.1) {
      setIsSpeaking(false);
      // æ¸…ç†å¤‡ç”¨å®šæ—¶å™¨
      if (playbackTimer) {
        clearTimeout(playbackTimer);
        setPlaybackTimer(null);
      }
    }
    
    // å½“éŸ³é¢‘æ’­æ”¾å®Œæˆæ—¶æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if (!audioPlayer.playing && !isGenerating && audioUri && audioPlayer.currentTime > 0) {
      // å»¶è¿Ÿæ¸…ç†ï¼Œç¡®ä¿éŸ³é¢‘å·²å®Œå…¨åœæ­¢
      setTimeout(() => {
        FileSystem.deleteAsync(audioUri, { idempotent: true });
        setAudioUri(null);
      }, 500);
    }
  }, [audioPlayer.playing, audioUri, audioPlayer.currentTime, audioPlayer.duration, isGenerating]);

  const speak = useCallback(async (text: string, voiceId?: string) => {
    if (!text.trim()) return;

    try {
      setError(null);
      setIsGenerating(true); // å¼€å§‹ç”Ÿæˆè¯­éŸ³
      setCurrentSegment(''); // æ¸…ç©ºå½“å‰æ®µè½
      
      // åœæ­¢å½“å‰æ’­æ”¾
      if (audioPlayer.playing) {
        audioPlayer.pause();
        audioPlayer.seekTo(0);
      }

      // æ¸…ç†ä¹‹å‰çš„éŸ³é¢‘æ–‡ä»¶
      if (audioUri) {
        FileSystem.deleteAsync(audioUri, { idempotent: true });
      }

      // ä¸´æ—¶ä½¿ç”¨æ™®é€šAPIï¼Œæµ‹è¯•åŸºæœ¬åŠŸèƒ½
      console.log('ğŸ”§ ä½¿ç”¨æ™®é€šAPIå¹¶åˆ›å»ºæ¨¡æ‹Ÿæ®µè½');
      
      // ä½¿ç”¨æ™®é€šAPIç”Ÿæˆè¯­éŸ³
      const newAudioUri = await generateSpeechFile(text, voiceId);
      
      // åˆ›å»ºæ¨¡æ‹Ÿçš„æ®µè½æ•°æ®ç”¨äºæµ‹è¯•
      const segments = createMockSegments(text);
      console.log('ğŸ“ åˆ›å»ºæ¨¡æ‹Ÿæ®µè½:', segments);
      
      // ä½¿ç”¨ replace æ–¹æ³•è®¾ç½®æ–°çš„éŸ³é¢‘æº
      audioPlayer.replace(newAudioUri);
      setAudioUri(newAudioUri);
      
      // ç­‰å¾…éŸ³é¢‘åŠ è½½å®Œæˆåæ’­æ”¾
      setTimeout(() => {
        audioPlayer.play();
        setIsGenerating(false);
        
        console.log('ğŸµ å¼€å§‹æ’­æ”¾éŸ³é¢‘ï¼Œæ®µè½æ•°:', segments.length);
        
        // å¼€å§‹ç›‘æ§æ®µè½æ’­æ”¾
        const segmentTimer = setInterval(() => {
          if (audioPlayer.playing) {
            const currentTime = audioPlayer.currentTime;
            const currentSegmentData = segments.find(s => 
              currentTime >= s.start && currentTime < s.end
            );
            
            if (currentSegmentData) {
              console.log('ğŸ“ æ›´æ–°å½“å‰æ®µè½:', currentSegmentData.text, `æ—¶é—´: ${currentTime}s`);
              setCurrentSegment(currentSegmentData.text);
            } else if (currentTime >= segments[segments.length - 1]?.end) {
              console.log('ğŸµ æ’­æ”¾å®Œæˆï¼Œæ¸…ç©ºæ®µè½');
              setCurrentSegment('');
              clearInterval(segmentTimer);
            }
          } else {
            console.log('ğŸµ åœæ­¢æ’­æ”¾ï¼Œæ¸…ç©ºæ®µè½');
            setCurrentSegment('');
            clearInterval(segmentTimer);
          }
        }, 100);
        
        setPlaybackTimer(segmentTimer);
      }, 100);

    } catch (err) {
      setError(err instanceof Error ? err.message : 'è¯­éŸ³åˆæˆå¤±è´¥');
      setIsGenerating(false);
      setIsSpeaking(false);
      setCurrentSegment('');
      console.error('ElevenLabs TTS Error:', err);
    }
  }, [audioPlayer, audioUri]);

  const stop = useCallback(async () => {
    try {
      if (audioPlayer.playing) {
        audioPlayer.pause();
        audioPlayer.seekTo(0);
      }
      
      // åœæ­¢æ‰€æœ‰çŠ¶æ€
      setIsGenerating(false);
      setIsSpeaking(false);
      setCurrentSegment(''); // æ¸…ç©ºå½“å‰æ®µè½
      
      // æ¸…ç†å¤‡ç”¨å®šæ—¶å™¨
      if (playbackTimer) {
        clearInterval(playbackTimer);
        setPlaybackTimer(null);
      }
      
      // æ¸…ç†ä¸´æ—¶éŸ³é¢‘æ–‡ä»¶
      if (audioUri) {
        FileSystem.deleteAsync(audioUri, { idempotent: true });
        setAudioUri(null);
      }
    } catch (err) {
      setError(err instanceof Error ? err.message : 'åœæ­¢æ’­æ”¾å¤±è´¥');
      setIsGenerating(false);
      setIsSpeaking(false); // ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿé‡ç½®çŠ¶æ€
      setCurrentSegment(''); // æ¸…ç©ºå½“å‰æ®µè½
      // æ¸…ç†å¤‡ç”¨å®šæ—¶å™¨
      if (playbackTimer) {
        clearInterval(playbackTimer);
        setPlaybackTimer(null);
      }
    }
  }, [audioPlayer, audioUri, playbackTimer]);

  return {
    isSpeaking,
    isGenerating,
    error,
    speak,
    stop,
    currentSegment,
  };
};